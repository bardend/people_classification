{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a08f46b-954f-479d-9986-616ac0f31c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "# Especifica la ruta donde guardaste el modelo\n",
    "model = load_model(\"model2/my_model_version_final_bon.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b55b450-ec04-481a-87b3-3d827cd415ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './will_smith.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRicardo_Ulloa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAida_Vallejo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#image contain more than face\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m image_Input \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./will_smith.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/IA/holi/lib/python3.8/site-packages/face_recognition/api.py:86\u001b[0m, in \u001b[0;36mload_image_file\u001b[0;34m(file, mode)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_file\u001b[39m(file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Loads an image file (.jpg, .png, etc) into a numpy array\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    :return: image contents as numpy array\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode:\n\u001b[1;32m     88\u001b[0m         im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mconvert(mode)\n",
      "File \u001b[0;32m~/Python/IA/holi/lib/python3.8/site-packages/PIL/Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './will_smith.jpeg'"
     ]
    }
   ],
   "source": [
    "names = ['Ricardo_Ulloa', 'Aida_Vallejo']\n",
    "#image contain more than face\n",
    "image_Input = face_recognition.load_image_file('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7e2fc-a3cd-4d65-8935-02edbad50535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#face location variable is like an array contain faces\n",
    "face_locations = face_recognition.face_locations(image_Input)\n",
    "# Iterate over the face locations\n",
    "for i, face_location in enumerate(face_locations):\n",
    "    # Get the coordinates of the face\n",
    "    top, right, bottom, left = face_location\n",
    "\n",
    "    # Extract the face from the image\n",
    "    face_image = image_Input[top:bottom, left:right]\n",
    "\n",
    "    # Convert the face image to a Pillow Image object\n",
    "    #\n",
    "    face_image = cv2.resize(face_image, (170, 170))\n",
    "    # Save the face image to a file\n",
    "    face_image = Image.fromarray(face_image)\n",
    "    #cv2.imwrite(\"face_found_{}.jpg\".format(i), face_image)\n",
    "    face_image.save(\"face_found_{}.jpg\".format(i))\n",
    "\n",
    "plt.imshow(image_Input)\n",
    "plt.show()\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------\")\n",
    "image_array = Image.fromarray(image_Input)\n",
    "draw = ImageDraw.Draw(image_array)  # Create an ImageDraw object\n",
    "for i ,(top, right, bottom, left)in enumerate(face_locations):\n",
    "    new_data=cv2.imread(\"face_found_{}.jpg\".format(i))\n",
    "    new_data=cv2.cvtColor(new_data,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(new_data)\n",
    "    plt.show()\n",
    "    predict_image=np.expand_dims(new_data, axis=0)\n",
    "    predict = model.predict(predict_image)\n",
    "    print(predict)\n",
    "    #return the index of the max predict\n",
    "    class_idx = np.argmax(predict)\n",
    "    #the classe name \n",
    "    class_name = names[class_idx]\n",
    "    max_prob = np.max(predict)*100\n",
    "    print(max_prob,\"%\")\n",
    "    text = class_name +\" \"+str(int(np.max(predict)*100) ) +\"%\"\n",
    "    #add text to the image\n",
    "    cv2.rectangle(image_Input,(left,top),(right, bottom),(0, 255, 0),thickness=2)  \n",
    "    cv2.putText(image_Input, text, (left, top), cv2.FONT_HERSHEY_SIMPLEX  , 0.5, (255, 0, 0), 2)\n",
    "    print(class_name)\n",
    "plt.imshow(image_Input)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1f055-1a95-47ab-8bb9-f6115fa5d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
